{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Markdown tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objective:\" data-toc-modified-id=\"Objective:-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objective:</a></span></li><li><span><a href=\"#Breaks\" data-toc-modified-id=\"Breaks-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Breaks</a></span><ul class=\"toc-item\"><li><span><a href=\"#Paragraph-Breaks\" data-toc-modified-id=\"Paragraph-Breaks-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Paragraph Breaks</a></span></li><li><span><a href=\"#Line-Breaks\" data-toc-modified-id=\"Line-Breaks-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Line Breaks</a></span><ul class=\"toc-item\"><li><span><a href=\"#Hard-Wrapping-and-Soft-Wrapping\" data-toc-modified-id=\"Hard-Wrapping-and-Soft-Wrapping-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Hard-Wrapping and Soft-Wrapping</a></span></li><li><span><a href=\"#Soft-Wrapping\" data-toc-modified-id=\"Soft-Wrapping-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Soft-Wrapping</a></span></li><li><span><a href=\"#Hard-Wrapping\" data-toc-modified-id=\"Hard-Wrapping-2.2.3\"><span class=\"toc-item-num\">2.2.3&nbsp;&nbsp;</span>Hard-Wrapping</a></span></li></ul></li><li><span><a href=\"#Section-Breaks\" data-toc-modified-id=\"Section-Breaks-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Section Breaks</a></span></li></ul></li><li><span><a href=\"#Headers\" data-toc-modified-id=\"Headers-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Headers</a></span></li><li><span><a href=\"#Block-Quotes\" data-toc-modified-id=\"Block-Quotes-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Block Quotes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Standard-Block-Quoting\" data-toc-modified-id=\"Standard-Block-Quoting-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Standard Block Quoting</a></span></li></ul></li><li><span><a href=\"#Lists\" data-toc-modified-id=\"Lists-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Lists</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ordered-Lists\" data-toc-modified-id=\"Ordered-Lists-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Ordered Lists</a></span></li><li><span><a href=\"#Bulleted-Lists\" data-toc-modified-id=\"Bulleted-Lists-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Bulleted Lists</a></span></li></ul></li><li><span><a href=\"#Hyperlink\" data-toc-modified-id=\"Hyperlink-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Hyperlink</a></span><ul class=\"toc-item\"><li><span><a href=\"#Automatic-Links\" data-toc-modified-id=\"Automatic-Links-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Automatic Links</a></span></li><li><span><a href=\"#Standard-Links\" data-toc-modified-id=\"Standard-Links-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Standard Links</a></span></li><li><span><a href=\"#Standard-Links-With-Mouse-Over-Titles\" data-toc-modified-id=\"Standard-Links-With-Mouse-Over-Titles-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Standard Links With Mouse-Over Titles</a></span></li><li><span><a href=\"#Reference-Links\" data-toc-modified-id=\"Reference-Links-6.4\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Reference Links</a></span></li><li><span><a href=\"#Notebook-Internal-Links\" data-toc-modified-id=\"Notebook-Internal-Links-6.5\"><span class=\"toc-item-num\">6.5&nbsp;&nbsp;</span>Notebook-Internal Links</a></span><ul class=\"toc-item\"><li><span><a href=\"#Standard-Notebook-Internal-Links-Without-Mouse-Over-Titles\" data-toc-modified-id=\"Standard-Notebook-Internal-Links-Without-Mouse-Over-Titles-6.5.1\"><span class=\"toc-item-num\">6.5.1&nbsp;&nbsp;</span>Standard Notebook-Internal Links Without Mouse-Over Titles</a></span></li><li><span><a href=\"#Standard-Notebook-Internal-Links-With-Mouse-Over-Titles\" data-toc-modified-id=\"Standard-Notebook-Internal-Links-With-Mouse-Over-Titles-6.5.2\"><span class=\"toc-item-num\">6.5.2&nbsp;&nbsp;</span>Standard Notebook-Internal Links With Mouse-Over Titles</a></span></li><li><span><a href=\"#Reference-Style-Notebook-Internal-Links\" data-toc-modified-id=\"Reference-Style-Notebook-Internal-Links-6.5.3\"><span class=\"toc-item-num\">6.5.3&nbsp;&nbsp;</span>Reference-Style Notebook-Internal Links</a></span></li></ul></li></ul></li><li><span><a href=\"#Table\" data-toc-modified-id=\"Table-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Table</a></span><ul class=\"toc-item\"><li><span><a href=\"#Cell-Justification\" data-toc-modified-id=\"Cell-Justification-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Cell Justification</a></span></li></ul></li><li><span><a href=\"#Style-and-Emphasis\" data-toc-modified-id=\"Style-and-Emphasis-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Style and Emphasis</a></span></li><li><span><a href=\"#LaTex-Math\" data-toc-modified-id=\"LaTex-Math-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>LaTex Math</a></span></li><li><span><a href=\"#Bibliographic-Support\" data-toc-modified-id=\"Bibliographic-Support-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Bibliographic Support</a></span></li><li><span><a href=\"#Other-functionality\" data-toc-modified-id=\"Other-functionality-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Other functionality</a></span><ul class=\"toc-item\"><li><span><a href=\"#Convert-jupyter-notebook-into-slides\" data-toc-modified-id=\"Convert-jupyter-notebook-into-slides-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>Convert jupyter notebook into slides</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective:\n",
    "- Get familiar with Jupyter notebook markdown language. More details to [the Jupyter Notebook User Manual](../reference/Jupyter%20Notebook%20Users%20Manual.ipynb)  \n",
    "    - Understand different type of cells  \n",
    "    - Know how to insert hyperlink  \n",
    "    - Know how to insert images   \n",
    "    - Know how to insert literature/references  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "## Breaks\n",
    "### Paragraph Breaks\n",
    "Paragraphs consist of one or more consecutive lines of text and they are separated by one or more blank lines. If a line contains only spaces, it is a blank line.\n",
    "### Line Breaks\n",
    "#### Hard-Wrapping and Soft-Wrapping\n",
    "If you're used to word processing software, you've been writing with automatically hard-wrapped lines and paragraphs. In a hard-wrapped paragraph the line breaks are not dependent on the size of the viewing window. If you click and drag your mouse to expand a word processing document, for example, the shape of the paragraphs and the length of the lines will not change. In other words, the length of a hard-wrapped line is determined either by the number of words in the line (in the case of word processing software where this number is predetermined and the program wraps for the user automatically), or individual intention (when a user manually presses an Enter or Return key to control exactly how long a line is).\n",
    "\n",
    "Soft-wrapped paragraphs and lines, however, do depend on the size of their viewing window. If you increase the size of a window where soft-wrapped paragraphs are displayed, they too will expand into longer lines, becoming shorter and wider to fill the increased window space horizontally. Unsurprising, then, if you narrow a window, soft-wrapped lines will shrink and the paragraphs will become longer vertically.\n",
    "\n",
    "Markdown, unlike most word processing software, does not automatically hard-wrap. If you want your paragraphs to have a particular or deliberate shape and size, you must insert your own break by __ending the line with two spaces__ and then typing Return.\n",
    "\n",
    "#### Soft-Wrapping\n",
    "blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah\n",
    "blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah\n",
    "\n",
    "#### Hard-Wrapping\n",
    "blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah  \n",
    "blah blah blah blah blah  \n",
    "blah blah blah blah blah blah blah blah blah  \n",
    "blah blah blah blah blah blah blah blah blah blah blah  \n",
    "blah blah blah blah blah  \n",
    "blah blah blah blah blah  \n",
    "blah blah blah blah blah blah blah blah blah blah blah blah blah\n",
    "\n",
    "### Section Breaks\n",
    "Section breaks can be represented by \"---\", \"\\*\\*\\*\", \"- - -\", \"* * *\"\n",
    "\n",
    "section 1\n",
    "- - -\n",
    "section 2\n",
    "***\n",
    "section 3\n",
    "* * *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "## Headers\n",
    "Header is just uing # in front of each header text. I am still not figure out how to control the auto numbering. The only way it works now is by setting it in the ToC. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T17:53:04.473105Z",
     "start_time": "2020-03-08T17:53:04.470415Z"
    }
   },
   "source": [
    "## Block Quotes\n",
    "### Standard Block Quoting\n",
    "By adding > or >> to show block quoting\n",
    "\n",
    ">blah blah block quote blah blah block quote blah blah block quote blah blah block quote blah blah block quote blah blah block quote blah blah block quote blah blah block quote\n",
    ">> nested nested  \n",
    "\n",
    ">blah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lists\n",
    "### Ordered Lists\n",
    "In Markdown, you can list items using numbers, a +, a -, or a *. However, if the first item in a list or sublist is numbered, Markdown will interpret the entire list as ordered and will automatically number the items linearly, no matter what character you use to denote any given separate item.\n",
    "\n",
    "0. Fruit:\n",
    "    1. Pears\n",
    "    0. Peaches\n",
    "    3. Plums\n",
    "    4. Apples \n",
    "        2. Granny Smith \n",
    "        7. Gala\n",
    "    * Oranges\n",
    "    - Berries \n",
    "        8. Strawberries \n",
    "        + Blueberries\n",
    "        * Raspberries\n",
    "    - Bananas\n",
    "9. Bread:\n",
    "    9. Whole Wheat\n",
    "        0. With oats on crust\n",
    "        0. Without oats on crust\n",
    "    0. Rye \n",
    "    0. White\n",
    "0. Dairy:\n",
    "    0. Milk\n",
    "        0. Whole\n",
    "        0. Skim\n",
    "    0. Cheese\n",
    "        0. Wisconsin Cheddar\n",
    "        0. Pepper Jack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T18:20:45.946357Z",
     "start_time": "2020-03-08T18:20:45.941929Z"
    }
   },
   "source": [
    "### Bulleted Lists\n",
    "If you begin your list or sublist with a +, a -, or a *, then Markdown will interpret the whole list as unordered and will use bullets regardless of the characters you type before any individual list item.\n",
    "\n",
    "* Fruit:\n",
    "    * Pears\n",
    "    0. Peaches\n",
    "    3. Plums\n",
    "    4. Apples \n",
    "        - Granny Smith \n",
    "        7. Gala\n",
    "    * Oranges\n",
    "    - Berries \n",
    "        - Strawberries \n",
    "        + Blueberries\n",
    "        * Raspberries\n",
    "    - Bananas\n",
    "9. Bread:\n",
    "    * Whole Wheat\n",
    "        * With oats on crust\n",
    "        0. Without oats on crust\n",
    "    + Rye \n",
    "    0. White\n",
    "0. Dairy:\n",
    "    * Milk\n",
    "        + Whole\n",
    "        0. Skim\n",
    "    - Cheese\n",
    "        - Wisconsin Cheddar\n",
    "        0. Pepper Jack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperlink\n",
    "### Automatic Links\n",
    "http://en.wikipedia.org\n",
    "\n",
    "\n",
    "### Standard Links\n",
    "`[click this link](http://en.wikipedia.org)`\n",
    "\n",
    "[click this link](http://en.wikipedia.org)\n",
    "\n",
    "### Standard Links With Mouse-Over Titles\n",
    "`[click this link](http://en.wikipedia.org \"Wikipedia\")`\n",
    "\n",
    "[click this link](http://en.wikipedia.org \"Wikipedia\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Links\n",
    "\n",
    "Suppose you are writing a document in which you intend to include many links. The format above is a little arduous and if you have to do it repeatedly while you're trying to focus on the content of what you're writing, it's going to be a really big pain.\n",
    "\n",
    "Fortunately, there is an alternative way to insert hyperlinks into your text, one where you indicate that there is a link, name that link, and then use the name to provide the actually URL later on when you're less in the writing zone. This method can be thought of as a \"reference-style\" link because it is similar to using in-text citations and then defining those citations later in a more detailed reference section or bibliography."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "This is [a reference of Chile]\n",
    "\n",
    "[a reference of Chile]: http://en.wikipedia.org/wiki/Chile \"Wikipedia Article About Chile\"\n",
    "```\n",
    "This is [a reference of Chile]\n",
    "\n",
    "[a reference of Chile]: http://en.wikipedia.org/wiki/Chile \"Wikipedia Article About Chile\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-08T18:36:31.748040Z",
     "start_time": "2020-03-08T18:36:31.742273Z"
    }
   },
   "source": [
    "### Notebook-Internal Links\n",
    "When you create a Header you also create a discrete location within your Notebook. This means that, just like you can link to a specific location on the web, you can also link to a Header Cell inside your Notebook. Internal links have very similar Markdown formatting to regular links. The only difference is that the name of the link, which is the URL in the case of external links, is just a hashtag plus the name of the Header Cell you are linking to (case-sensitive) with dashes in between every word. If you hover your mouse over a Header Cell, a blue Greek pi letter will appear next to your title. If you click on it, the URL at the top of your window will change and the internal link to that section will appear last in the address. You can copy and paste it in order to make an internal link inside a Markdown Cell.\n",
    "\n",
    "#### Standard Notebook-Internal Links Without Mouse-Over Titles\n",
    "```[Here's a link to the section of Automatic Section Numbering](#Automatic-Section-Numbering)```\n",
    "\n",
    "[Here's a link to the section of Automatic Section Numbering](#Automatic-Section-Numbering)\n",
    "\n",
    "#### Standard Notebook-Internal Links With Mouse-Over Titles\n",
    "```[Here's a link to the section on lists](#Lists \"Lists\")```\n",
    "\n",
    "[Here's a link to the section on lists](#Lists \"Lists\")\n",
    "\n",
    "#### Reference-Style Notebook-Internal Links\n",
    "```\n",
    "[Here's a link to the section on Table of Contents Support][TOC]\n",
    "[TOC]: #Table-of-Contents-Support\n",
    "```\n",
    "\n",
    "[Here's a link to the section on Table of Contents Support][TOC]\n",
    "[TOC]: #Table-of-Contents-Support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is [a reference] [lfskdhflhslgfh333676]\n",
    "\n",
    "[lfskdhflhslgfh333676]: http://en.wikipedia.org/wiki/Chile \"Wikipedia Article About Chile\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table\n",
    "In Markdown, you can make a table by using vertical bars and dashes to define the cell and header borders:\n",
    "```\n",
    "|Header|Header|Header|Header|\n",
    "|------|------|------|------|\n",
    "|Cell  |Cell  |Cell  | Cell |\n",
    "|Cell  |Cell  |Cell  | Cell |\n",
    "|Cell  |Cell  |Cell  | Cell |\n",
    "|Cell  |Cell  |Cell  | Cell |\n",
    "```\n",
    "you don't need to include all of those dashes, vertical bars, and spaces for Markdown to understand that you're making a table. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|Header|Header|Header|Header|\n",
    "|:-:|:-|-:|:-:|\n",
    "|Cell| Cell  |Cell  | Cell |\n",
    "|Cell  |Cell  |Cell  | Cell |\n",
    "|Cell  |Cell  |Cell  | Cell |\n",
    "|Cell  |Cell  |Cell  | Cell |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cell Justification\n",
    "You can make the cell centered, right-justified and left-justfied by indicating in the line ```:-:|-:|:-|```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Style and Emphasis\n",
    "\n",
    "```\n",
    "*Italics*\n",
    "```\n",
    ">*Italics*\n",
    "\n",
    "\n",
    "```\n",
    "_Italics_\n",
    "```\n",
    ">_Italics_\n",
    "\n",
    "```\n",
    "**Bold**\n",
    "```\n",
    ">**Bold**\n",
    "\n",
    "```\n",
    "__Bold__\n",
    "```\n",
    ">__Bold__\n",
    "\n",
    "Note: If you want actual asterisks or underscores to appear in your text, you can use the backslash escape function like this:\n",
    "```\n",
    "\\*awesome asterisks\\* and \\_incredible under scores\\_\n",
    "*awesome asterisks* and _incredible under scores_\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LaTex Math\n",
    "\n",
    "Jupyter Notebooks' Markdown cells support LateX for formatting mathematical equations. To tell Markdown to interpret your text as LaTex, surround your input with dollar signs like this:\n",
    "```$z=\\dfrac{2x}{3y}$``` --> $z=\\dfrac{2x}{3y}$\n",
    "\n",
    "An equation can be very complex:\n",
    "```$F(k) = \\int_{-\\infty}^{\\infty} f(x) e^{2\\pi i k} dx$```\n",
    "\n",
    "$F(k) = \\int_{-\\infty}^{\\infty} f(x) e^{2\\pi i k} dx$\n",
    "\n",
    "If you want your LaTex equations to be indented towards the center of the cell, surround your input with two dollar signs on each side like this: ```$$2x+3y=z$$```\n",
    "\n",
    "$$2x+3y=z$$\n",
    "\n",
    " \n",
    "For a comprehensive guide to the mathematical symbols and notations supported by Jupyter Notebooks' Markdown cells, check out https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Typesetting%20Equations.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliographic Support\n",
    "\n",
    "Prerequests:\n",
    "1. Create a Bibtex database\n",
    "2. Use cite command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a reference [cite](#cite-10.1021/acs.jcim.8b00769)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--bibtex \n",
    " \n",
    "@article{10.1021/acs.jcim.8b00769, \n",
    "  author = {Cai, Chuipu and Guo, Pengfei and Zhou, Yadi and Zhou, Jingwei and Wang, Qi and Zhang, Fengxue and Fang, Jiansong and Cheng, Feixiong}, \n",
    "  title = {{Deep Learning-Based Prediction of Drug-Induced Cardiotoxicity}}, \n",
    "  issn = {1549-9596}, \n",
    "  doi = {10.1021/acs.jcim.8b00769}, \n",
    "  pmid = {30715873}, \n",
    "  abstract = {{Blockade of the human ether-à-go-go-related gene (hERG) channel by small molecules induces the prolongation of the QT interval which leads to fatal cardiotoxicity and accounts for the withdrawal or severe restrictions on the use of many approved drugs. In this study, we develop a deep learning approach, termed deephERG, for prediction of hERG blockers of small molecules in drug discovery and postmarketing surveillance. In total, we assemble 7,889 compounds with well-defined experimental data on the hERG and with diverse chemical structures. We find that deephERG models built by a multitask deep neural network (DNN) algorithm outperform those built by single-task DNN, naı̈ve Bayes (NB), support vector machine (SVM), random forest (RF), and graph convolutional neural network (GCNN). Specifically, the area under the receiver operating characteristic curve (AUC) value for the best model of deephERG is 0.967 on the validation set. Furthermore, based on 1,824 U.S. Food and Drug Administration (FDA) approved drugs, 29.6\\% drugs are computationally identified to have potential hERG inhibitory activities by deephERG, highlighting the importance of hERG risk assessment in early drug discovery. Finally, we showcase several novel predicted hERG blockers on approved antineoplastic agents, which are validated by clinical case reports, experimental evidence, and the literature. In summary, this study presents a powerful deep learning-based tool for risk assessment of hERG-mediated cardiotoxicities in drug discovery and postmarketing surveillance.}}, \n",
    "  pages = {1073--1084}, \n",
    "  number = {3}, \n",
    "  volume = {59}, \n",
    "  journal = {Journal of Chemical Information and Modeling}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{10.1021/acs.jcim.9b00626, \n",
    "  author = {Abbasi, Karim and Poso, Antti and Ghasemi, Jahanbakhsh and Amanlou, Massoud and Masoudi-Nejad, Ali}, \n",
    "  title = {{Deep Transferable Compound Representation Across Domains and Tasks for Low Data Drug Discovery}}, \n",
    "  issn = {1549-9596}, \n",
    "  doi = {10.1021/acs.jcim.9b00626}, \n",
    "  pmid = {31661955}, \n",
    "  abstract = {{The main problem of small molecule-based drug discovery is to find a candidate molecule with increased pharmacological activity, proper ADME, and low toxicity. Recently, machine learning has driven a significant contribution to drug discovery. However, many machine learning methods, such as deep learning-based approaches, require a large amount of training data to form accurate predictions for unseen data. In lead optimization step, the amount of available biological data on small molecule compounds is low, which makes it a challenging problem to apply machine learning methods. The main goal of this study is to design a new approach to handle these situations. To this end, source assay (auxiliary assay) knowledge is utilized to learn a better model to predict the property of new compounds in the target assay. Up to now, the current approaches did not consider that source and target assays are adapted to different target groups with different compounds distribution. In this paper, we propose a new architecture by utilizing graph convolutional network and adversarial domain adaptation network to tackle this issue. To evaluate the proposed approach, we applied it to Tox21, ToxCast, SIDER, HIV, and BACE collections. The results showed the effectiveness of the proposed approach in transferring the related knowledge from source to target data set.}}, \n",
    "  pages = {4528--4539}, \n",
    "  number = {11}, \n",
    "  volume = {59}, \n",
    "  journal = {Journal of Chemical Information and Modeling}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{10.1021/acscentsci.6b00367, \n",
    "  author = {Altae-Tran, Han and Ramsundar, Bharath and Pappu, Aneesh S and Pande, Vijay}, \n",
    "  title = {{Low data drug discovery with one-shot learning}}, \n",
    "  issn = {2374-7943}, \n",
    "  doi = {10.1021/acscentsci.6b00367}, \n",
    "  pmid = {28470045}, \n",
    "  abstract = {{Recent advances in machine learning have made significant contributions to drug discovery. Deep neural networks in particular have been demonstrated to provide significant boosts in predictive power when inferring the properties and activities of small-molecule compounds (Ma, J. et al. J. Chem. Inf. Model. 2015, 55, 263–274). However, the applicability of these techniques has been limited by the requirement for large amounts of training data. In this work, we demonstrate how one-shot learning can be used to significantly lower the amounts …}}, \n",
    "  pages = {283--293}, \n",
    "  number = {4}, \n",
    "  volume = {3}, \n",
    "  journal = {ACS central science}, \n",
    "  year = {2017}\n",
    "}\n",
    "@article{undefined, \n",
    "  author = {Ash, Jeremy R and Hughes-Oliver, Jacqueline M}, \n",
    "  title = {{Confidence Bands and Hypothesis Test Methods for Recall and Precision Curves at Extremely Small Fractions with Applications to Drug Discovery}}, \n",
    "  eprint = {1912.09526}, \n",
    "  abstract = {{In virtual screening for drug discovery, recall curves are used to assess the performance of ranking algorithms, in which recall is a function of the fraction of data prioritized for experimental testing. Unfortunately, researchers almost never consider the uncertainty in the estimation of the recall curve when benchmarking algorithms. We confirm that a recently developed procedure for estimating pointwise confidence intervals for recall curves -- and closely related variants, such as precision curves -- can be applied to a variety of simulated data sets representative of those typically encountered in virtual screening. Since it is more desirable in benchmarks to present the uncertainty of performance over a range of testing fractions, we extend the pointwise confidence interval procedure to allow for the estimation of confidence bands for these curves. We also present hypothesis test methods to determine significant differences between the curves for competing algorithms. We show these methods have high power to detect significant differences at a range of small fractions typically tested, while maintaining control of type I error rate. These methods enable statistically rigorous comparisons of virtual screening algorithms using a metric that quantifies the aspect of performance that is of primary interest.}}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{10.1016/j.yrtph.2015.12.006, \n",
    "  author = {Barber, Chris and Cayley, Alex and Hanser, Thierry and Harding, Alex and Heghes, Crina and Vessey, Jonathan D and Werner, Stephane and Weiner, Sandy K and Wichard, Joerg and Giddings, Amanda and Glowienke, Susanne and Parenty, Alexis and Brigo, Alessandro and Spirkl, Hans-Peter and Amberg, Alexander and Kemper, Ray and Greene, Nigel}, \n",
    "  title = {{Evaluation of a statistics-based Ames mutagenicity QSAR model and interpretation of the results obtained}}, \n",
    "  issn = {0273-2300}, \n",
    "  doi = {10.1016/j.yrtph.2015.12.006}, \n",
    "  pmid = {26708083}, \n",
    "  abstract = {{ The relative wealth of bacterial mutagenicity data available in the public literature means that in silico quantitative/qualitative structure activity relationship (QSAR) systems can readily be built for this endpoint. A good means of evaluating the performance of such systems is to use private unpublished data sets, which generally represent a more distinct chemical space than publicly available test sets and, as a result, provide a greater challenge to the model. However, raw performance metrics should not be the only factor considered when judging this type of software since expert interpretation of the results obtained may allow for further improvements in predictivity. Enough information should be provided by a QSAR to allow the user to make general, scientifically-based arguments in order to assess and overrule predictions when necessary. With all this in mind, we sought to validate the performance of the statistics-based in vitro bacterial mutagenicity prediction system Sarah Nexus (version 1.1) against private test data sets supplied by nine different pharmaceutical companies. The results of these evaluations were then analysed in order to identify findings presented by the model which would be useful for the user to take into consideration when interpreting the results and making their final decision about the mutagenic potential of a given compound.}}, \n",
    "  pages = {7--20}, \n",
    "  number = {Mutagenesis 24 2009}, \n",
    "  volume = {76}, \n",
    "  journal = {Regulatory Toxicology and Pharmacology}, \n",
    "  year = {2016}\n",
    "}\n",
    "@article{10.1021/acs.jcim.9b00571, \n",
    "  author = {Bellmann, Louis and Penner, Patrick and Rarey, Matthias}, \n",
    "  title = {{Connected Subgraph Fingerprints: Representing Molecules Using Exhaustive Subgraph Enumeration}}, \n",
    "  issn = {1549-9596}, \n",
    "  doi = {10.1021/acs.jcim.9b00571}, \n",
    "  pmid = {31652055}, \n",
    "  abstract = {{Molecular fingerprints are an efficient and widely used method for similarity-driven virtual screening. Most fingerprint methods can be distinguished by the class of structural features considered. The Connected Subgraph Fingerprint (CSFP) overcomes this limitation and regards all structural features of a compound. This results in a more complete feature space and high adaptive potential to certain application scenarios. The novel descriptor surpasses widely used fingerprint methods in some cases and opens the way for topological search in combinatorial fragment spaces.}}, \n",
    "  pages = {4625--4635}, \n",
    "  number = {11}, \n",
    "  volume = {59}, \n",
    "  journal = {Journal of Chemical Information and Modeling}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{undefined, \n",
    "  author = {Bjerrum, Esben}, \n",
    "  title = {{SMILES Enumeration as Data Augmentation for Neural Network Modeling of Molecules}}, \n",
    "  eprint = {1703.07076}, \n",
    "  abstract = {{Simplified Molecular Input Line Entry System (SMILES) is a single line text representation of a unique molecule. One molecule can however have multiple SMILES strings, which is a reason that canonical SMILES have been defined, which ensures a one to one correspondence between SMILES string and molecule. Here the fact that multiple SMILES represent the same molecule is explored as a technique for data augmentation of a molecular QSAR dataset modeled by a long short term memory (LSTM) cell based neural network. The augmented dataset was 130 times bigger than the original. The network trained with the augmented dataset shows better performance on a test set when compared to a model built with only one canonical SMILES string per molecule. The correlation coefficient R2 on the test set was improved from 0.56 to 0.66 when using SMILES enumeration, and the root mean square error (RMS) likewise fell from 0.62 to 0.55. The technique also works in the prediction phase. By taking the average per molecule of the predictions for the enumerated SMILES a further improvement to a correlation coefficient of 0.68 and a RMS of 0.52 was found.}}, \n",
    "  year = {2017}\n",
    "}\n",
    "@article{undefined, \n",
    "  author = {Capela, Fabio and Nouchi, Vincent and Deursen, Ruud and Tetko, Igor V and Godin, Guillaume}, \n",
    "  title = {{Multitask Learning On Graph Neural Networks Applied To Molecular Property Predictions}}, \n",
    "  eprint = {1910.13124}, \n",
    "  abstract = {{Prediction of molecular properties, including physico-chemical properties, is a challenging task in chemistry. Herein we present a new state-of-the-art multitask prediction method based on existing graph neural network models. We have used different architectures for our models and the results clearly demonstrate that multitask learning can improve model performance. Additionally, a significant reduction of variance in the models has been observed. Most importantly, datasets with a small amount of data points reach better results without the need of augmentation.}}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{10.1021/acs.jcim.6b00601, \n",
    "  author = {Coley, Connor W and Barzilay, Regina and Green, William H and Jaakkola, Tommi S and Jensen, Klavs F}, \n",
    "  title = {{Convolutional Embedding of Attributed Molecular Graphs for Physical Property Prediction.}}, \n",
    "  issn = {1549-9596}, \n",
    "  doi = {10.1021/acs.jcim.6b00601}, \n",
    "  pmid = {28696688}, \n",
    "  abstract = {{The task of learning an expressive molecular representation is central to developing quantitative structure-activity and property relationships. Traditional approaches rely on group additivity rules, empirical measurements or parameters, or generation of thousands of descriptors. In this paper, we employ a convolutional neural network for this embedding task by treating molecules as undirected graphs with attributed nodes and edges. Simple atom and bond attributes are used to construct atom-specific feature vectors that take into account the local chemical environment using different neighborhood radii. By working directly with the full molecular graph, there is a greater opportunity for models to identify important features relevant to a prediction task. Unlike other graph-based approaches, our atom featurization preserves molecule-level spatial information that significantly enhances model performance. Our models learn to identify important features of atom clusters for the prediction of aqueous solubility, octanol solubility, melting point, and toxicity. Extensions and limitations of this strategy are discussed.}}, \n",
    "  pages = {1757--1772}, \n",
    "  number = {8}, \n",
    "  volume = {57}, \n",
    "  journal = {Journal of chemical information and modeling}, \n",
    "  year = {2017}\n",
    "}\n",
    "@article{undefined, \n",
    "  author = {Dahl, George E and Jaitly, Navdeep and Salakhutdinov, Ruslan}, \n",
    "  title = {{Multi-task Neural Networks for QSAR Predictions}}, \n",
    "  eprint = {1406.1231}, \n",
    "  abstract = {{Although artificial neural networks have occasionally been used for Quantitative Structure-Activity/Property Relationship (QSAR/QSPR) studies in the past, the literature has of late been dominated by other machine learning techniques such as random forests. However, a variety of new neural net techniques along with successful applications in other domains have renewed interest in network approaches. In this work, inspired by the winning team's use of neural networks in a recent QSAR competition, we used an artificial neural network to learn a function that predicts activities of compounds for multiple assays at the same time. We conducted experiments leveraging recent methods for dealing with overfitting in neural networks as well as other tricks from the neural networks literature. We compared our methods to alternative methods reported to perform well on these tasks and found that our neural net methods provided superior performance.}}, \n",
    "  year = {2014}\n",
    "}\n",
    "@article{undefined, \n",
    "  author = {Dhami, Devendra Singh and Kunapuli, Gautam and Page, David and Natarajan, Sriraam}, \n",
    "  title = {{Predicting Drug-Drug Interactions from Molecular Structure Images}}, \n",
    "  eprint = {1911.06356}, \n",
    "  abstract = {{Predicting and discovering drug-drug interactions (DDIs) is an important problem and has been studied extensively both from medical and machine learning point of view. Almost all of the machine learning approaches have focused on text data or textual representation of the structural data of drugs. We present the first work that uses drug structure images as the input and utilizes a Siamese convolutional network architecture to predict DDIs.}}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{Anonymous:6f6, \n",
    "  author = {Duvenaud, David and Maclaurin, Dougal and Aguilera-Iparraguirre, Jorge and Gómez-Bombarelli, Rafael and Hirzel, Timothy and Aspuru-Guzik, Alán and Adams, Ryan P}, \n",
    "  title = {{Convolutional Networks on Graphs for Learning Molecular Fingerprints}}, \n",
    "  eprint = {1509.09292}, \n",
    "  abstract = {{We introduce a convolutional neural network that operates directly on graphs. These networks allow end-to-end learning of prediction pipelines whose inputs are graphs of arbitrary size and shape. The architecture we present generalizes standard molecular feature extraction methods based on circular fingerprints. We show that these data-driven features are more interpretable, and have better predictive performance on a variety of tasks.}}, \n",
    "  year = {2015}, \n",
    "  rating = {5}\n",
    "}\n",
    "@article{10.1021/ci400573c, \n",
    "  author = {Eklund, Martin and Norinder, Ulf and Boyer, Scott and Carlsson, Lars}, \n",
    "  title = {{Choosing feature selection and learning algorithms in QSAR.}}, \n",
    "  issn = {1549-9596}, \n",
    "  doi = {10.1021/ci400573c}, \n",
    "  pmid = {24460242}, \n",
    "  abstract = {{Feature selection is an important part of contemporary QSAR analysis. In a recently published paper, we investigated the performance of different feature selection methods in a large number of in silico experiments conducted using real QSAR datasets. However, an interesting question that we did not address is whether certain feature selection methods are better than others in combination with certain learning methods, in terms of producing models with high prediction accuracy. In this report we extend our work from the previous investigation by using four different feature selection methods (wrapper, ReliefF, MARS, and elastic nets), together with eight learners (MARS, elastic net, random forest, SVM, neural networks, multiple linear regression, PLS, kNN) in an empirical investigation to address this question. The results indicate that state-of-the-art learners (random forest, SVM, and neural networks) do not gain prediction accuracy from feature selection, and we found no evidence that a certain feature selection is particularly well-suited for use in combination with a certain learner.}}, \n",
    "  pages = {837--43}, \n",
    "  number = {3}, \n",
    "  volume = {54}, \n",
    "  journal = {Journal of chemical information and modeling}, \n",
    "  year = {2014}\n",
    "}\n",
    "@article{10.1038/d41586-019-03846-0, \n",
    "  author = {Freedman, David H.}, \n",
    "  title = {{Hunting for New Drugs with AI}}, \n",
    "  issn = {0028-0836}, \n",
    "  doi = {10.1038/d41586-019-03846-0}, \n",
    "  abstract = {{The pharmaceutical industry is in a drug-discovery slump. How much can AI help? The pharmaceutical industry is in a drug-discovery slump. How much can AI help?}}, \n",
    "  pages = {S49--S53}, \n",
    "  number = {7787}, \n",
    "  volume = {576}, \n",
    "  journal = {Nature}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{10.1021/acs.jcim.9b00718, \n",
    "  author = {Fu, Li and Liu, Lu and Yang, Zhi-Jiang and Li, Pan and Ding, Jun-Jie and Yun, Yong-Huan and Lu, Ai-Ping and Hou, Ting-Jun and Cao, Dong-Sheng}, \n",
    "  title = {{Systematic Modeling of log D7.4 Based on Ensemble Machine Learning, Group Contribution, and Matched Molecular Pair Analysis}}, \n",
    "  issn = {1549-9596}, \n",
    "  doi = {10.1021/acs.jcim.9b00718}, \n",
    "  pmid = {31869226}, \n",
    "  abstract = {{Lipophilicity, as evaluated by the n-octanol/buffer solution distribution coefficient at pH = 7.4 (logD7.4), is a major determinant of various absorption, distribution, metabolism, elimination and toxicology (ADMET) parameters of drug candidates. In this study, we developed several quantitative structure-property relationship (QSPR) models to predict logD7.4 based on a large and structurally diverse data set. Eight popular machine learning algorithms were employed to build the prediction models with 43 molecular descriptors selected by a wrapper feature selection method. The results demonstrated XGBoost yielded better prediction performance than any other single model (RT2 = 0.906 and RMSET = 0.395). However, the consensus model from the top three models could continue to improve the prediction performance (RT2 = 0.922 and RMSET=0.359). The robustness, reliability, and generalization ability of the models were strictly evaluated by the Y-randomization test and applicability domain analysis. Moreover, the group contribution model based on 110 atom types and the local models for different ionization states were also established and compared with the global models. The results demonstrated that the descriptor-based consensus model is superior to the group contribution method, and the local models have no advantage over the global models. Finally, matched molecular pair (MMP) analysis and descriptor importance analysis were performed to extract transformation rules and give some explanations related to logD7.4. In conclusion, we believe that the consensus model developed in this study can be used as a reliable and promising tool to evaluate logD7.4 in drug discovery.}}, \n",
    "  journal = {Journal of Chemical Information and Modeling}, \n",
    "  year = {2020}\n",
    "}\n",
    "@article{undefined, \n",
    "  author = {Gilmer, Justin and Schoenholz, Samuel S and Riley, Patrick F and Vinyals, Oriol and Dahl, George E}, \n",
    "  title = {{Neural Message Passing for Quantum Chemistry}}, \n",
    "  eprint = {1704.01212}, \n",
    "  abstract = {{Supervised learning on molecules has incredible potential to be useful in chemistry, drug discovery, and materials science. Luckily, several promising and closely related neural network models invariant to molecular symmetries have already been described in the literature. These models learn a message passing algorithm and aggregation function to compute a function of their entire input graph. At this point, the next step is to find a particularly effective variant of this general approach and apply it to chemical prediction benchmarks until we either solve them or reach the limits of the approach. In this paper, we reformulate existing models into a single common framework we call Message Passing Neural Networks (MPNNs) and explore additional novel variations within this framework. Using MPNNs we demonstrate state of the art results on an important molecular property prediction benchmark, results we believe are strong enough to justify retiring this benchmark.}}, \n",
    "  year = {2017}, \n",
    "  rating = {5}\n",
    "}\n",
    "@article{Gómez-Bombarelli:2018378, \n",
    "  author = {Gómez-Bombarelli, Rafael and Wei, Jennifer N and Duvenaud, David and Hernández-Lobato, José and Sánchez-Lengeling, Benjamín and Sheberla, Dennis and Aguilera-Iparraguirre, Jorge and Hirzel, Timothy D and Adams, Ryan P and Aspuru-Guzik, Alán}, \n",
    "  title = {{Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules}}, \n",
    "  issn = {2374-7943}, \n",
    "  doi = {10.1021/acscentsci.7b00572}, \n",
    "  pmid = {29532027}, \n",
    "  abstract = {{We report a method to convert discrete representations of molecules to and from a multidimensional continuous representation. This model allows us to generate new molecules for efficient exploration and optimization through open-ended spaces of chemical compounds. A deep neural network was trained on hundreds of thousands of existing chemical structures to construct three coupled functions: an encoder, a decoder, and a predictor. The encoder converts the discrete representation of a molecule into a real-valued continuous vector, and the decoder converts these continuous vectors back to discrete molecular representations. The predictor estimates chemical properties from the latent continuous vector representation of the molecule. Continuous representations of molecules allow us to automatically generate novel chemical structures by performing simple operations in the latent space, such as decoding random vectors, perturbing known chemical structures, or interpolating between molecules. Continuous representations also allow the use of powerful gradient-based optimization to efficiently guide the search for optimized functional compounds. We demonstrate our method in the domain of drug-like molecules and also in a set of molecules with fewer that nine heavy atoms.}}, \n",
    "  journal = {ACS Central Science}, \n",
    "  year = {2018}\n",
    "}\n",
    "@incollection{10.1021/bk-2019-1326.ch005, \n",
    "  author = {Green, Darren V S}, \n",
    "  title = {{Using Machine Learning To Inform Decisions in DrugDiscovery: An Industry Perspective}}, \n",
    "  isbn = {9780841235052}, \n",
    "  pages = {81--101}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{10.1021/acs.jcim.8b00553, \n",
    "  author = {Grenet, Ingrid and Merlo, Kevin and Comet, Jean-Paul and Tertiaux, Romain and Rouquié, David and Dayan, Frédéric}, \n",
    "  title = {{Stacked Generalization with Applicability Domain Outperforms Simple QSAR on in Vitro Toxicological Data}}, \n",
    "  issn = {1549-9596}, \n",
    "  doi = {10.1021/acs.jcim.8b00553}, \n",
    "  pmid = {30735402}, \n",
    "  abstract = {{The development of in silico tools able to predict bioactivity and toxicity of chemical substances is a powerful solution envisioned to assess toxicity as early as possible. To enable the development of such tools, the ToxCast program has generated and made publicly available in vitro bioactivity data for thousands of compounds. The goal of the present study is to characterize and explore the data from ToxCast in terms of Machine Learning capability. For this, a large scale analysis on the entire database has been performed to build models to predict bioactivities measured in in vitro assays. Simple classical QSAR algorithms (ANN, SVM, LDA, random forest, and Bayesian) were first applied on the data, and the results of these algorithms suggested that they do not seem to be well-suited for data sets with a high proportion of inactive compounds. The study then showed for the first time that the use of an ensemble method named \"Stacked generalization\" could improve the model performance on this type of data. Indeed, for 61\\% of 483 models, the Stacked method led to models with higher performance. Moreover, the combination of this ensemble method with an applicability domain filter allows one to assess the reliability of the predictions for further compound prioritization. In particular we showed that for 50\\% of the models, the ROC score is better if we do not consider the compounds that are not within the applicability domain.}}, \n",
    "  pages = {1486--1496}, \n",
    "  number = {4}, \n",
    "  volume = {59}, \n",
    "  journal = {Journal of Chemical Information and Modeling}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{undefined, \n",
    "  author = {Hamilton, William L and Ying, Rex and Leskovec, Jure}, \n",
    "  title = {{Representation Learning on Graphs: Methods and Applications}}, \n",
    "  eprint = {1709.05584}, \n",
    "  abstract = {{Machine learning on graphs is an important and ubiquitous task with applications ranging from drug design to friendship recommendation in social networks. The primary challenge in this domain is finding a way to represent, or encode, graph structure so that it can be easily exploited by machine learning models. Traditionally, machine learning approaches relied on user-defined heuristics to extract features encoding structural information about a graph (e.g., degree statistics or kernel functions). However, recent years have seen a surge in approaches that automatically learn to encode graph structure into low-dimensional embeddings, using techniques based on deep learning and nonlinear dimensionality reduction. Here we provide a conceptual review of key advancements in this area of representation learning on graphs, including matrix factorization-based methods, random-walk based algorithms, and graph neural networks. We review methods to embed individual nodes as well as approaches to embed entire (sub)graphs. In doing so, we develop a unified framework to describe these recent approaches, and we highlight a number of important applications and directions for future work.}}, \n",
    "  year = {2017}\n",
    "}\n",
    "@article{10.1186/s12859-018-2523-5, \n",
    "  author = {Hirohara, Maya and Saito, Yutaka and Koda, Yuki and Sato, Kengo and Sakakibara, Yasubumi}, \n",
    "  title = {{Convolutional neural network based on SMILES representation of compounds for detecting chemical motif}}, \n",
    "  doi = {10.1186/s12859-018-2523-5}, \n",
    "  pmid = {30598075}, \n",
    "  abstract = {{Previous studies have suggested deep learning to be a highly effective approach for screening lead compounds for new drugs. Several deep learning models have been developed by addressing the use of various kinds of fingerprints and graph convolution architectures. However, these methods are either advantageous or disadvantageous depending on whether they (1) can distinguish structural differences including chirality of compounds, and (2) can automatically discover effective features. We developed another deep learning model for compound classification. In this method, we constructed a distributed representation of compounds based on the SMILES notation, which linearly represents a compound structure, and applied the SMILES-based representation to a convolutional neural network (CNN). The use of SMILES allows us to process all types of compounds while incorporating a broad range of structure information, and representation learning by CNN automatically acquires a low-dimensional representation of input features. In a benchmark experiment using the TOX 21 dataset, our method outperformed conventional fingerprint methods, and performed comparably against the winning model of the TOX 21 Challenge. Multivariate analysis confirmed that the chemical space consisting of the features learned by SMILES-based representation learning adequately expressed a richer feature space that enabled the accurate discrimination of compounds. Using motif detection with the learned filters, not only important known structures (motifs) such as protein-binding sites but also structures of unknown functional groups were detected. The source code of our SMILES-based convolutional neural network software in the deep learning framework Chainer is available at http://www.dna.bio.keio.ac.jp/smiles/, and the dataset used for performance evaluation in this work is available at the same URL.}}, \n",
    "  pages = {526}, \n",
    "  number = {S19}, \n",
    "  volume = {19}, \n",
    "  journal = {BMC Bioinformatics}, \n",
    "  year = {2018}\n",
    "}\n",
    "@article{undefined, \n",
    "  author = {Honda, Shion and Shi, Shoi and Ueda, Hiroki R}, \n",
    "  title = {{SMILES Transformer: Pre-trained Molecular Fingerprint for Low Data Drug Discovery}}, \n",
    "  eprint = {1911.04738}, \n",
    "  abstract = {{In drug-discovery-related tasks such as virtual screening, machine learning is emerging as a promising way to predict molecular properties. Conventionally, molecular fingerprints (numerical representations of molecules) are calculated through rule-based algorithms that map molecules to a sparse discrete space. However, these algorithms perform poorly for shallow prediction models or small datasets. To address this issue, we present SMILES Transformer. Inspired by Transformer and pre-trained language models from natural language processing, SMILES Transformer learns molecular fingerprints through unsupervised pre-training of the sequence-to-sequence language model using a huge corpus of SMILES, a text representation system for molecules. We performed benchmarks on 10 datasets against existing fingerprints and graph-based methods and demonstrated the superiority of the proposed algorithms in small-data settings where pre-training facilitated good generalization. Moreover, we define a novel metric to concurrently measure model accuracy and data efficiency.}}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{10.1021/acs.jcim.9b00694, \n",
    "  author = {Hong, Seung Hwan and Ryu, Seongok and Lim, Jaechang and Kim, Woo Youn}, \n",
    "  title = {{Molecular Generative Model Based On Adversarially Regularized Autoencoder}}, \n",
    "  issn = {1549-9596}, \n",
    "  doi = {10.1021/acs.jcim.9b00694}, \n",
    "  pmid = {31820983}, \n",
    "  abstract = {{Deep generative models are attracting great attention as a new promising approach for molecular design. A variety of models reported so far are based on either a variational autoencoder (VAE) or a generative adversarial network (GAN), but they have limitations such as low validity and uniqueness. Here, we propose a new type of model based on an adversarially regularized autoencoder (ARAE). It basically uses latent variables like VAE, but the distribution of the latent variables is estimated by adversarial training like in GAN. The latter is intended to avoid both the insufficiently flexible approximation of posterior distribution in VAE and the difficulty in handling discrete variables in GAN. Our benchmark study showed that ARAE indeed outperformed conventional models in terms of validity, uniqueness, and novelty per generated molecule. We also demonstrated a successful conditional generation of drug-like molecules with ARAE for the control of both cases of single and multiple properties. As a potential real-world application, we could generate epidermal growth factor receptor inhibitors sharing the scaffolds of known active molecules while satisfying drug-like conditions simultaneously.}}, \n",
    "  journal = {Journal of Chemical Information and Modeling}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{undefined, \n",
    "  author = {Hu, Weihua and Liu, Bowen and Gomes, Joseph and Zitnik, Marinka and Liang, Percy and Pande, Vijay and Leskovec, Jure}, \n",
    "  title = {{Pre-training Graph Neural Networks}}, \n",
    "  eprint = {1905.12265}, \n",
    "  abstract = {{Many applications of machine learning in science and medicine, including molecular property and protein function prediction, can be cast as problems of predicting some properties of graphs, where having good graph representations is critical. However, two key challenges in these domains are (1) extreme scarcity of labeled data due to expensive lab experiments, and (2) needing to extrapolate to test graphs that are structurally different from those seen during training. In this paper, we explore pre-training to address both of these challenges. In particular, working with Graph Neural Networks (GNNs) for representation learning of graphs, we wish to obtain node representations that (1) capture similarity of nodes' network neighborhood structure, (2) can be composed to give accurate graph-level representations, and (3) capture domain-knowledge. To achieve these goals, we propose a series of methods to pre-train GNNs at both the node-level and the graph-level, using both unlabeled data and labeled data from related auxiliary supervised tasks. We perform extensive evaluation on two applications, molecular property and protein function prediction. We observe that performing only graph-level supervised pre-training often leads to marginal performance gain or even can worsen the performance compared to non-pre-trained models. On the other hand, effectively combining both node- and graph-level pre-training techniques significantly improves generalization to out-of-distribution graphs, consistently outperforming non-pre-trained GNNs across 8 datasets in molecular property prediction (resp. 40 tasks in protein function prediction), with the average ROC-AUC improvement of 7.2\\% (resp. 11.7\\%).}}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{undefined, \n",
    "  author = {Jiang, Peihong and Doan, Hieu and Madireddy, Sandeep and Assary, Rajeev Surendran and Balaprakash, Prasanna}, \n",
    "  title = {{Value-Added Chemical Discovery Using Reinforcement Learning}}, \n",
    "  eprint = {1911.07630}, \n",
    "  abstract = {{Computer-assisted synthesis planning aims to help chemists find better reaction pathways faster. Finding viable and short pathways from sugar molecules to value-added chemicals can be modeled as a retrosynthesis planning problem with a catalyst allowed. This is a crucial step in efficient biomass conversion. The traditional computational chemistry approach to identifying possible reaction pathways involves computing the reaction energies of hundreds of intermediates, which is a critical bottleneck in silico reaction discovery. Deep reinforcement learning has shown in other domains that a well-trained agent with little or no prior human knowledge can surpass human performance. While some effort has been made to adapt machine learning techniques to the retrosynthesis planning problem, value-added chemical discovery presents unique challenges. Specifically, the reaction can occur in several different sites in a molecule, a subtle case that has never been treated in previous works. With a more versatile formulation of the problem as a Markov decision process, we address the problem using deep reinforcement learning techniques and present promising preliminary results.}}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{10.1007/s10822-016-9938-8, \n",
    "  author = {Kearnes, Steven and McCloskey, Kevin and Berndl, Marc and Pande, Vijay and Riley, Patrick}, \n",
    "  title = {{Molecular graph convolutions: moving beyond fingerprints}}, \n",
    "  issn = {0920-654X}, \n",
    "  doi = {10.1007/s10822-016-9938-8}, \n",
    "  pmid = {27558503}, \n",
    "  eprint = {1603.00856}, \n",
    "  abstract = {{Molecular “fingerprints” encoding structural information are the workhorse of cheminformatics and machine learning in drug discovery applications. However, fingerprint representations necessarily emphasize particular aspects of the molecular structure while ignoring others, rather than allowing the model to make data-driven decisions. We describe molecular graph convolutions, a machine learning architecture for learning from undirected graphs, specifically small molecules. Graph convolutions use a simple encoding of the molecular graph—atoms, bonds, distances, etc.—which allows the model to take greater advantage of information in the graph structure. Although graph convolutions do not outperform all fingerprint-based methods, they (along with other graph-based methods) represent a new paradigm in ligand-based virtual screening with exciting opportunities for future improvement.}}, \n",
    "  pages = {595--608}, \n",
    "  number = {8}, \n",
    "  volume = {30}, \n",
    "  journal = {Journal of Computer-Aided Molecular Design}, \n",
    "  year = {2016}\n",
    "}\n",
    "@article{10.1021/acs.jcim.8b00672, \n",
    "  author = {Li, Xiuming and Yan, Xin and Gu, Qiong and Zhou, Huihao and Wu, Di and Xu, Jun}, \n",
    "  title = {{DeepChemStable: Chemical Stability Prediction with an Attention-Based Graph Convolution Network}}, \n",
    "  issn = {1549-9596}, \n",
    "  doi = {10.1021/acs.jcim.8b00672}, \n",
    "  pmid = {30764613}, \n",
    "  abstract = {{In the drug discovery process, unstable compounds in storage can lead to false positive or false negative bioassay conclusions. Prediction of the chemical stability of a compound by de novo methods is complex. Chemical instability prediction is commonly based on a model derived from empirical data. The COMDECOM (COMpound DECOMposition) project provides the empirical data for prediction of chemical stability. Models such as the extended-connectivity fingerprint and atom center fragments were built from the COMDECOM data and used for estimation of chemical stability, but deficits in the existing models remain. In this paper, we report DeepChemStable, a model employing an attention-based graph convolution network based on the COMDECOM data. The main advantage of this method is that DeepChemStable is an end-to-end model, which does not predefine structural fingerprint features, but instead, dynamically learns structural features and associates the features through the learning process of an attention-based graph convolution network. The previous ChemStable program relied on a rule-based method to reduce the false negatives. DeepChemStable, on the other hand, reduces the risk of false negatives without using a rule-based method. Because minimizing the rate of false negatives is a greater concern for instability prediction, this feature is a major improvement. This model achieves an AUC value of 84.7\\%, recall rate of 79.8\\%, and 10-fold stratified cross-validation accuracy of 79.1\\%.}}, \n",
    "  pages = {1044--1049}, \n",
    "  number = {3}, \n",
    "  volume = {59}, \n",
    "  journal = {Journal of Chemical Information and Modeling}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{10.1021/acs.jcim.9b00387, \n",
    "  author = {Lim, Jaechang and Ryu, Seongok and Park, Kyubyong and Choe, Yo Joong and Ham, Jiyeon and Kim, Woo Youn}, \n",
    "  title = {{Predicting Drug-target Interaction Using a Novel Graph Neural Network with 3D Structure-embedded Graph Representation}}, \n",
    "  issn = {1549-9596}, \n",
    "  doi = {10.1021/acs.jcim.9b00387}, \n",
    "  pmid = {31443612}, \n",
    "  abstract = {{We propose a novel deep learning approach for predicting drug-target interaction using a graph neural network. We introduce a distance-aware graph attention algorithm to differentiate various types of intermolecular interactions. Furthermore, we extract the graph feature of intermolecular interactions directly from the 3D structural information on the protein-ligand binding pose. Thus, the model can learn key features for accurate predictions of drug-target interaction rather than just memorize certain patterns of ligand molecules. As a result, our model shows better performance than docking and other deep learning methods for both virtual screening (AUROC of 0.968 for the DUD-E test set) and pose prediction (AUROC of 0.935 for the PDBbind test set). In addition, it can reproduce the natural population distribution of active molecules and inactive molecules.}}, \n",
    "  pages = {3981--3988}, \n",
    "  number = {9}, \n",
    "  volume = {59}, \n",
    "  journal = {Journal of Chemical Information and Modeling}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{10.1021/acs.jmedchem.7b00487, \n",
    "  author = {Lombardo, Franco and Desai, Prashant V and Arimoto, Rieko and Desino, Kelly E and Fischer, Holger and Keefer, Christopher E and Petersson, Carl and Winiwarter, Susanne and Broccatelli, Fabio}, \n",
    "  title = {{In Silico Absorption, Distribution, Metabolism, Excretion, and Pharmacokinetics (ADME-PK): Utility and Best Practices. An Industry Perspective from the International Consortium for Innovation through Quality in Pharmaceutical Development.}}, \n",
    "  issn = {0022-2623}, \n",
    "  doi = {10.1021/acs.jmedchem.7b00487}, \n",
    "  pmid = {28609624}, \n",
    "  abstract = {{In silico tools to investigate absorption, distribution, metabolism, excretion, and pharmacokinetics (ADME-PK) properties of new chemical entities are an integral part of the current industrial drug discovery paradigm. While many companies are active in the field, scientists engaged in this area do not necessarily share the same background and have limited resources when seeking guidance on how to initiate and maintain an in silico ADME-PK infrastructure in an industrial setting. This work summarizes the views of a group of industrial in silico and experimental ADME scientists, participating in the In Silico ADME Working Group, a subgroup of the International Consortium for Innovation through Quality in Pharmaceutical Development (IQ) Drug Metabolism Leadership Group. This overview on the benefits, caveats, and impact of in silico ADME-PK should serve as a resource for medicinal chemists, computational chemists, and DMPK scientists working in drug design to increase their knowledge in the area.}}, \n",
    "  pages = {9097--9113}, \n",
    "  number = {22}, \n",
    "  volume = {60}, \n",
    "  journal = {Journal of medicinal chemistry}, \n",
    "  year = {2017}\n",
    "}\n",
    "@article{undefined, \n",
    "  author = {Maragakis, Paul and Nisonoff, Hunter and Cole, Brian and Shaw, David E}, \n",
    "  title = {{A deep-learning view of chemical space designed to facilitate drug discovery}}, \n",
    "  eprint = {2002.02948}, \n",
    "  abstract = {{Drug discovery projects entail cycles of design, synthesis, and testing that yield a series of chemically related small molecules whose properties, such as binding affinity to a given target protein, are progressively tailored to a particular drug discovery goal. The use of deep learning technologies could augment the typical practice of using human intuition in the design cycle, and thereby expedite drug discovery projects. Here we present DESMILES, a deep neural network model that advances the state of the art in machine learning approaches to molecular design. We applied DESMILES to a previously published benchmark that assesses the ability of a method to modify input molecules to inhibit the dopamine receptor D2, and DESMILES yielded a 77\\% lower failure rate compared to state-of-the-art models. To explain the ability of DESMILES to hone molecular properties, we visualize a layer of the DESMILES network, and further demonstrate this ability by using DESMILES to tailor the same molecules used in the D2 benchmark test to dock more potently against seven different receptors.}}, \n",
    "  year = {2020}\n",
    "}\n",
    "@article{10.1021/acs.jcim.9b00266, \n",
    "  author = {Mater, Adam C and Coote, Michelle L}, \n",
    "  title = {{Deep Learning in Chemistry}}, \n",
    "  issn = {1549-9596}, \n",
    "  doi = {10.1021/acs.jcim.9b00266}, \n",
    "  pmid = {31194543}, \n",
    "  abstract = {{Machine learning enables computers to address problems by learning from data. Deep learning is a type of machine learning that uses a hierarchical recombination of features to extract pertinent information and then learn the patterns represented in the data. Over the last eight years, its abilities have increasingly been applied to a wide variety of chemical challenges, from improving computational chemistry to drug and materials design and even synthesis planning. This review aims to explain the concepts of deep learning to chemists from any background and follows this with an overview of the diverse applications demonstrated in the literature. We hope that this will empower the broader chemical community to engage with this burgeoning field and foster the growing movement of deep learning accelerated chemistry.}}, \n",
    "  pages = {2545--2559}, \n",
    "  number = {6}, \n",
    "  volume = {59}, \n",
    "  journal = {Journal of Chemical Information and Modeling}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{undefined, \n",
    "  author = {Minnich, Amanda J and McLoughlin, Kevin and Tse, Margaret and Deng, Jason and Weber, Andrew and Murad, Neha and Madej, Benjamin D and Ramsundar, Bharath and Rush, Tom and Calad-Thomson, Stacie and Brase, Jim and Allen, Jonathan E}, \n",
    "  title = {{AMPL: A Data-Driven Modeling Pipeline for Drug Discovery}}, \n",
    "  eprint = {1911.05211}, \n",
    "  abstract = {{One of the key requirements for incorporating machine learning into the drug discovery process is complete reproducibility and traceability of the model building and evaluation process. With this in mind, we have developed an end-to-end modular and extensible software pipeline for building and sharing machine learning models that predict key pharma-relevant parameters. The ATOM Modeling PipeLine, or AMPL, extends the functionality of the open source library DeepChem and supports an array of machine learning and molecular featurization tools. We have benchmarked AMPL on a large collection of pharmaceutical datasets covering a wide range of parameters. As a result of these comprehensive experiments, we have found that physicochemical descriptors and deep learning-based graph representations significantly outperform traditional fingerprints in the characterization of molecular features. We have also found that dataset size is directly correlated to prediction performance, and that single-task deep learning models only outperform shallow learners if there is sufficient data. Likewise, dataset size has a direct impact on model predictivity, independent of comprehensive hyperparameter model tuning. Our findings point to the need for public dataset integration or multi-task/transfer learning approaches. Lastly, we found that uncertainty quantification (UQ) analysis may help identify model error; however, efficacy of UQ to filter predictions varies considerably between datasets and featurization/model types. AMPL is open source and available for download at http://github.com/ATOMconsortium/AMPL.}}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{10.1021/acs.jctc.8b00959, \n",
    "  author = {Musil, Félix and Willatt, Michael J and Langovoy, Mikhail A and Ceriotti, Michele}, \n",
    "  title = {{Fast and Accurate Uncertainty Estimation in Chemical Machine Learning}}, \n",
    "  issn = {1549-9618}, \n",
    "  doi = {10.1021/acs.jctc.8b00959}, \n",
    "  pmid = {30605342}, \n",
    "  abstract = {{We present a scheme to obtain an inexpensive and reliable estimate of the uncertainty associated with the predictions of a machine-learning model of atomic and molecular properties. The scheme is based on resampling, with multiple models being generated based on subsampling of the same training data. The accuracy of the uncertainty prediction can be benchmarked by maximum likelihood estimation, which can also be used to correct for correlations between resampled models and to improve the performance of the uncertainty estimation by a cross-validation procedure. In the case of sparse Gaussian Process Regression models, this resampled estimator can be evaluated at negligible cost. We demonstrate the reliability of these estimates for the prediction of molecular and materials energetics and for the estimation of nuclear chemical shieldings in molecular crystals. Extension to estimate the uncertainty in energy differences, forces, or other correlated predictions is straightforward. This method can be easily applied to other machine-learning schemes and will be beneficial to make data-driven predictions more reliable and to facilitate training-set optimization and active-learning strategies.}}, \n",
    "  pages = {906--915}, \n",
    "  number = {2}, \n",
    "  volume = {15}, \n",
    "  journal = {Journal of Chemical Theory and Computation}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{undefined, \n",
    "  author = {Musil, Felix and Willatt, Michael J and Langovoy, Mikhail A and Ceriotti, Michele}, \n",
    "  title = {{Fast and Accurate Uncertainty Estimation in Chemical Machine Learning}}, \n",
    "  eprint = {1809.07653}, \n",
    "  abstract = {{We present a scheme to obtain an inexpensive and reliable estimate of the uncertainty associated with the predictions of a machine-learning model of atomic and molecular properties. The scheme is based on resampling, with multiple models being generated based on sub-sampling of the same training data. The accuracy of the uncertainty prediction can be benchmarked by maximum likelihood estimation, which can also be used to correct for correlations between resampled models, and to improve the performance of the uncertainty estimation by a cross-validation procedure. In the case of sparse Gaussian Process Regression models, this resampled estimator can be evaluated at negligible cost. We demonstrate the reliability of these estimates for the prediction of molecular energetics, and for the estimation of nuclear chemical shieldings in molecular crystals. Extension to estimate the uncertainty in energy differences, forces, or other correlated predictions is straightforward. This method can be easily applied to other machine learning schemes, and will be beneficial to make data-driven predictions more reliable, and to facilitate training-set optimization and active-learning strategies.}}, \n",
    "  year = {2018}\n",
    "}\n",
    "@article{10.1126/sciadv.aap7885, \n",
    "  author = {Popova, Mariya and Isayev, Olexandr and Tropsha, Alexander}, \n",
    "  title = {{Deep reinforcement learning for de novo drug design}}, \n",
    "  issn = {2375-2548}, \n",
    "  doi = {10.1126/sciadv.aap7885}, \n",
    "  pmid = {30050984}, \n",
    "  eprint = {1711.10907}, \n",
    "  abstract = {{We have devised and implemented a novel computational strategy for de novo design of molecules with desired properties termed ReLeaSE (Reinforcement Learning for Structural Evolution). On the basis of deep and reinforcement learning (RL) approaches, ReLeaSE integrates two deep neural networks—generative and predictive—that are trained separately but are used jointly to generate novel targeted chemical libraries. ReLeaSE uses simple representation of molecules by their simplified molecular-input line-entry system (SMILES) strings only. Generative models are trained with a stack-augmented memory network to produce chemically feasible SMILES strings, and predictive models are derived to forecast the desired properties of the de novo–generated compounds. In the first phase of the method, generative and predictive models are trained separately with a supervised learning algorithm. In the second phase, both models are trained jointly with the RL approach to bias the generation of new chemical structures toward those with the desired physical and/or biological properties. In the proof-of-concept study, we have used the ReLeaSE method to design chemical libraries with a bias toward structural complexity or toward compounds with maximal, minimal, or specific range of physical properties, such as melting point or hydrophobicity, or toward compounds with inhibitory activity against Janus protein kinase 2. The approach proposed herein can find a general use for generating targeted chemical libraries of novel compounds optimized for either a single desired property or multiple properties.}}, \n",
    "  pages = {eaap7885}, \n",
    "  number = {7}, \n",
    "  volume = {4}, \n",
    "  journal = {Science Advances}, \n",
    "  year = {2018}\n",
    "}\n",
    "@article{undefined, \n",
    "  author = {Preuer, Kristina and Klambauer, Günter and Rippmann, Friedrich and Hochreiter, Sepp and Unterthiner, Thomas}, \n",
    "  title = {{Interpretable Deep Learning in Drug Discovery}}, \n",
    "  eprint = {1903.02788}, \n",
    "  abstract = {{Without any means of interpretation, neural networks that predict molecular properties and bioactivities are merely black boxes. We will unravel these black boxes and will demonstrate approaches to understand the learned representations which are hidden inside these models. We show how single neurons can be interpreted as classifiers which determine the presence or absence of pharmacophore- or toxicophore-like structures, thereby generating new insights and relevant knowledge for chemistry, pharmacology and biochemistry. We further discuss how these novel pharmacophores/toxicophores can be determined from the network by identifying the most relevant components of a compound for the prediction of the network. Additionally, we propose a method which can be used to extract new pharmacophores from a model and will show that these extracted structures are consistent with literature findings. We envision that having access to such interpretable knowledge is a crucial aid in the development and design of new pharmaceutically active molecules, and helps to investigate and understand failures and successes of current methods.}}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{10.1038/nrd3439-c1, \n",
    "  author = {Prinz, Florian and Schlange, Thomas and Asadullah, Khusru}, \n",
    "  title = {{Believe it or not: how much can we rely on published data on potential drug targets?}}, \n",
    "  issn = {1474-1776}, \n",
    "  doi = {10.1038/nrd3439-c1}, \n",
    "  pmid = {21892149}, \n",
    "  pages = {712--712}, \n",
    "  number = {9}, \n",
    "  volume = {10}, \n",
    "  journal = {Nature Reviews Drug Discovery}, \n",
    "  year = {2011}\n",
    "}\n",
    "@article{10.1021/ci100050t, \n",
    "  author = {Rogers, David and Hahn, Mathew}, \n",
    "  title = {{Extended-Connectivity Fingerprints}}, \n",
    "  issn = {1549-9596}, \n",
    "  doi = {10.1021/ci100050t}, \n",
    "  pmid = {20426451}, \n",
    "  abstract = {{ Extended-connectivity fingerprints (ECFPs) are a novel class of topological fingerprints for molecular characterization. Historically, topological fingerprints were developed for substructure and similarity searching. ECFPs were developed specifically for structure−activity modeling. ECFPs are circular fingerprints with a number of useful qualities: they can be very rapidly calculated; they are not predefined and can represent an essentially infinite number of different molecular features (including stereochemical information); their features represent the presence of particular substructures, allowing easier interpretation of analysis results; and the ECFP algorithm can be tailored to generate different types of circular fingerprints, optimized for different uses. While the use of ECFPs has been widely adopted and validated, a description of their implementation has not previously been presented in the literature.}}, \n",
    "  pages = {742--754}, \n",
    "  number = {5}, \n",
    "  volume = {50}, \n",
    "  journal = {Journal of Chemical Information and Modeling}, \n",
    "  year = {2010}\n",
    "}\n",
    "@article{undefined, \n",
    "  author = {Scalia, Gabriele and Grambow, Colin A and Pernici, Barbara and Li, Yi-Pei and Green, William H}, \n",
    "  title = {{Evaluating Scalable Uncertainty Estimation Methods for DNN-Based Molecular Property Prediction}}, \n",
    "  eprint = {1910.03127}, \n",
    "  abstract = {{Advances in deep neural network (DNN) based molecular property prediction have recently led to the development of models of remarkable accuracy and generalization ability, with graph convolution neural networks (GCNNs) reporting state-of-the-art performance for this task. However, some challenges remain and one of the most important that needs to be fully addressed concerns uncertainty quantification. DNN performance is affected by the volume and the quality of the training samples. Therefore, establishing when and to what extent a prediction can be considered reliable is just as important as outputting accurate predictions, especially when out-of-domain molecules are targeted. Recently, several methods to account for uncertainty in DNNs have been proposed, most of which are based on approximate Bayesian inference. Among these, only a few scale to the large datasets required in applications. Evaluating and comparing these methods has recently attracted great interest, but results are generally fragmented and absent for molecular property prediction. In this paper, we aim to quantitatively compare scalable techniques for uncertainty estimation in GCNNs. We introduce a set of quantitative criteria to capture different uncertainty aspects, and then use these criteria to compare MC-Dropout, deep ensembles, and bootstrapping, both theoretically in a unified framework that separates aleatoric/epistemic uncertainty and experimentally on the QM9 dataset. Our experiments quantify the performance of the different uncertainty estimation methods and their impact on uncertainty-related error reduction. Our findings indicate that ensembling and bootstrapping consistently outperform MC-Dropout, with different context-specific pros and cons. Our analysis also leads to a better understanding of the role of aleatoric/epistemic uncertainty and highlights the challenge posed by out-of-domain uncertainty.}}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{10.1109/tnn.2008.2005605, \n",
    "  author = {Scarselli, F and Gori, M and Tsoi, Ah Chung and Hagenbuchner, M and Monfardini, G}, \n",
    "  title = {{The Graph Neural Network Model}}, \n",
    "  issn = {1045-9227}, \n",
    "  doi = {10.1109/tnn.2008.2005605}, \n",
    "  pmid = {19068426}, \n",
    "  abstract = {{Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function \\$\\textbackslashtau (\\{\\textbackslashmmb G\\},n)\\textbackslashin I\\textbackslash!\\textbackslash!R \\textasciicircum\\{m\\}\\$ that maps a graph \\$\\{\\textbackslashmmb G\\}\\$ and one of its nodes \\$n\\$ into an \\$m\\$-dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities.}}, \n",
    "  pages = {61--80}, \n",
    "  number = {1}, \n",
    "  volume = {20}, \n",
    "  journal = {IEEE Transactions on Neural Networks}, \n",
    "  year = {2009}\n",
    "}\n",
    "@article{10.1021/acs.jcim.9b00460, \n",
    "  author = {Schneckener, Sebastian and Grimbs, Sergio and Hey, Jessica and Menz, Stephan and Osmers, Maren and Schaper, Steffen and Hillisch, Alexander and Göller, Andreas H}, \n",
    "  title = {{Prediction of Oral Bioavailability in Rats: Transferring Insights from in Vitro Correlations to (Deep) Machine Learning Models Using in Silico Model Outputs and Chemical Structure Parameters}}, \n",
    "  issn = {1549-9596}, \n",
    "  doi = {10.1021/acs.jcim.9b00460}, \n",
    "  pmid = {31714067}, \n",
    "  abstract = {{Oral administration of drug products is a strict requirement in many medical indications. Therefore, bioavailability prediction models are of high importance for prioritization of compound candidates in the drug discovery process. However, oral exposure and bioavailability are difficult to predict, as they are the result of various highly complex factors and/or processes influenced by the physicochemical properties of a compound, such as solubility, lipophilicity, or charge state, as well as by interactions with the organism, for instance, metabolism or membrane permeation. In this study, we assess whether it is possible to predict intravenous (iv) or oral drug exposure and oral bioavailability in rats. As input parameters, we use (i) six experimentally determined in vitro and physicochemical endpoints, namely, membrane permeation, free fraction, metabolic stability, solubility, pKa value, and lipophilicity; (ii) the outputs of six in silico absorption, distribution, metabolism, and excretion models trained on the same endpoints, or (iii) the chemical structure encoded as fingerprints or simplified molecular input line entry system strings. The underlying data set for the models is an unprecedented collection of almost 1900 data points with high-quality in vivo experiments performed in rats. We find that drug exposure after iv administration can be predicted similarly well using hybrid models with in vitro- or in silico-predicted endpoints as inputs, with fold change errors (FCE) of 2.28 and 2.08, respectively. The FCEs for exposure after oral administration are higher, and here, the prediction from in vitro inputs performs significantly better in comparison to in silico-based models with FCEs of 3.49 and 2.40, respectively, most probably reflecting the higher complexity of oral bioavailability. Simplifying the prediction task to a binary alert for low oral bioavailability, based only on chemical structure, we achieve accuracy and precision close to 70\\%.}}, \n",
    "  pages = {4893--4905}, \n",
    "  number = {11}, \n",
    "  volume = {59}, \n",
    "  journal = {Journal of Chemical Information and Modeling}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{10.1021/acscentsci.9b00576, \n",
    "  author = {Schwaller, Philippe and Laino, Teodoro and Gaudin, Théophile and Bolgar, Peter and Hunter, Christopher A and Bekas, Costas and Lee, Alpha A}, \n",
    "  title = {{Molecular Transformer: A Model for Uncertainty-Calibrated Chemical Reaction Prediction}}, \n",
    "  issn = {2374-7943}, \n",
    "  doi = {10.1021/acscentsci.9b00576}, \n",
    "  pmid = {31572784}, \n",
    "  eprint = {1811.02633}, \n",
    "  abstract = {{Organic synthesis is one of the key stumbling blocks in medicinal chemistry. A necessary yet unsolved step in planning synthesis is solving the forward problem: given reactants and reagents, predict the products. Similar to other work, we treat reaction prediction as a machine translation problem between SMILES strings of reactants-reagents and the products. We show that a multi-head attention Molecular Transformer model outperforms all algorithms in the literature, achieving a top-1 accuracy above 90\\% on a common benchmark dataset. Our algorithm requires no handcrafted rules, and accurately predicts subtle chemical transformations. Crucially, our model can accurately estimate its own uncertainty, with an uncertainty score that is 89\\% accurate in terms of classifying whether a prediction is correct. Furthermore, we show that the model is able to handle inputs without reactant-reagent split and including stereochemistry, which makes our method universally applicable.}}, \n",
    "  pages = {1572--1583}, \n",
    "  number = {9}, \n",
    "  volume = {5}, \n",
    "  journal = {ACS Central Science}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{10.1021/ci100104j, \n",
    "  author = {Shen, Jie and Cheng, Feixiong and Xu, You and Li, Weihua and Tang, Yun}, \n",
    "  title = {{Estimation of ADME Properties with Substructure Pattern Recognition}}, \n",
    "  issn = {1549-9596}, \n",
    "  doi = {10.1021/ci100104j}, \n",
    "  pmid = {20578727}, \n",
    "  abstract = {{Over the past decade, absorption, distribution, metabolism, and excretion (ADME) property evaluation has become one of the most important issues in the process of drug discovery and development. Since in vivo and in vitro evaluations are costly and laborious, in silico techniques had been widely used to estimate ADME properties of chemical compounds. Traditional prediction methods usually try to build a functional relationship between a set of molecular descriptors and a given ADME property. Although traditional methods have been successfully used in many cases, the accuracy and efficiency of molecular descriptors must be concerned. Herein, we report a new classification method based on substructure pattern recognition, in which each molecule is represented as a substructure pattern fingerprint based on a predefined substructure dictionary, and then a support vector machine (SVM) algorithm is applied to build the prediction model. Therefore, a direct connection between substructures and molecular properties is built. The most important substructure patterns can be identified via the information gain analysis, which could help to interpret the models from a medicinal chemistry perspective. Afterward, this method was verified with two data sets, one for blood-brain barrier (BBB) penetration and the other for human intestinal absorption (HIA). The results demonstrated that the overall predictive accuracies of the best HIA model for the training and test sets were 98.5 and 98.8\\%, and the overall predictive accuracies of the best BBB model for the training and test sets were 98.8 and 98.4\\%, which confirmed the reliability of our method. In the additional validations, the predictive accuracies were 94 and 69.5\\% for the HIA and the BBB models, respectively. Moreover, some of the representative key substructure patterns which significantly correlated with the HIA and BBB penetration properties were also presented.}}, \n",
    "  pages = {1034--1041}, \n",
    "  number = {6}, \n",
    "  volume = {50}, \n",
    "  journal = {Journal of Chemical Information and Modeling}, \n",
    "  year = {2010}\n",
    "}\n",
    "@article{10.1021/acs.jcim.6b00591, \n",
    "  author = {Sheridan, Robert P and Wang, Wei and Liaw, Andy and Ma, Junshui and Gifford, Eric M}, \n",
    "  title = {{Extreme Gradient Boosting as a Method for Quantitative Structure-Activity Relationships.}}, \n",
    "  issn = {1549-9596}, \n",
    "  doi = {10.1021/acs.jcim.6b00591}, \n",
    "  pmid = {27958738}, \n",
    "  abstract = {{In the pharmaceutical industry it is common to generate many QSAR models from training sets containing a large number of molecules and a large number of descriptors. The best QSAR methods are those that can generate the most accurate predictions but that are not overly expensive computationally. In this paper we compare eXtreme Gradient Boosting (XGBoost) to random forest and single-task deep neural nets on 30 in-house data sets. While XGBoost has many adjustable parameters, we can define a set of standard parameters at which XGBoost makes predictions, on the average, better than those of random forest and almost as good as those of deep neural nets. The biggest strength of XGBoost is its speed. Whereas efficient use of random forest requires generating each tree in parallel on a cluster, and deep neural nets are usually run on GPUs, XGBoost can be run on a single CPU in less than a third of the wall-clock time of either of the other methods.}}, \n",
    "  pages = {2353--2360}, \n",
    "  number = {12}, \n",
    "  volume = {56}, \n",
    "  journal = {Journal of chemical information and modeling}, \n",
    "  year = {2016}\n",
    "}\n",
    "@article{10.1038/nrd.2017.194, \n",
    "  author = {Shih, Hsin-Pei and Zhang, Xiaodan and Aronov, Alex M.}, \n",
    "  title = {{Drug discovery effectiveness from the standpoint of therapeutic mechanisms and indications}}, \n",
    "  issn = {1474-1776}, \n",
    "  doi = {10.1038/nrd.2017.194}, \n",
    "  pmid = {29075002}, \n",
    "  abstract = {{We analysed the past 20 years of drug project history with the aim of understanding more about how the pharmaceutical industry has been performing with regard to therapeutic mechanisms and their intended indications.The analysis suggests that industry output in terms of successful projects in this period has come primarily from a limited set of well-validated therapeutic mechanisms.The analysis highlights inefficiencies in the industry due to continued investment in frequently discontinued therapeutic mechanisms, indicating that the industry could benefit from paying more attention to lessons learned from other projects and avoiding initiating projects for previously studied failed therapeutic mechanisms without rigorous and independent validation.The analysis indicates that the majority of ongoing projects are pursuing novel mechanism–indication pairs, even in the indications with existing therapeutics, which is highly encouraging. We analysed the past 20 years of drug project history with the aim of understanding more about how the pharmaceutical industry has been performing with regard to therapeutic mechanisms and their intended indications. The analysis suggests that industry output in terms of successful projects in this period has come primarily from a limited set of well-validated therapeutic mechanisms. The analysis highlights inefficiencies in the industry due to continued investment in frequently discontinued therapeutic mechanisms, indicating that the industry could benefit from paying more attention to lessons learned from other projects and avoiding initiating projects for previously studied failed therapeutic mechanisms without rigorous and independent validation. The analysis indicates that the majority of ongoing projects are pursuing novel mechanism–indication pairs, even in the indications with existing therapeutics, which is highly encouraging. Shih and colleagues analyse comprehensive industry-wide data on drug development projects pursued during the past 20 years, classified according to the mechanism and indication for each project. Their findings indicate several points and trends that may be useful in understanding and improving the productivity of the pharmaceutical industry, including areas with substantial success or failure and the relative extent of novelty in completed and ongoing projects. The productivity of the pharmaceutical industry has been widely discussed in recent years, particularly with regard to concerns that substantial expenditures on research and development have failed to translate into approved drugs. Various analyses of this productivity challenge have focused on aspects such as attrition rates at particular clinical phases or the physicochemical properties of drug candidates, but relatively little attention has been paid to how the industry has performed from the standpoint of the choice of therapeutic mechanisms and their intended indications. This article examines what the pharmaceutical industry has achieved in this respect by analysing comprehensive industry-wide data on the mechanism–indication pairs that have been investigated during the past 20 years. Our findings indicate several points and trends that we hope will be useful in understanding and improving the productivity of the industry, including areas in which the industry has had substantial success or failure and the relative extent of novelty in completed and ongoing projects.}}, \n",
    "  pages = {19--33}, \n",
    "  number = {1}, \n",
    "  volume = {17}, \n",
    "  journal = {Nature Reviews Drug Discovery}, \n",
    "  year = {2018}\n",
    "}\n",
    "@article{undefined, \n",
    "  author = {Shindo, Hiroyuki and Matsumoto, Yuji}, \n",
    "  title = {{Gated Graph Recursive Neural Networks for Molecular Property Prediction}}, \n",
    "  eprint = {1909.00259}, \n",
    "  abstract = {{Molecule property prediction is a fundamental problem for computer-aided drug discovery and materials science. Quantum-chemical simulations such as density functional theory (DFT) have been widely used for calculating the molecule properties, however, because of the heavy computational cost, it is difficult to search a huge number of potential chemical compounds. Machine learning methods for molecular modeling are attractive alternatives, however, the development of expressive, accurate, and scalable graph neural networks for learning molecular representations is still challenging. In this work, we propose a simple and powerful graph neural networks for molecular property prediction. We model a molecular as a directed complete graph in which each atom has a spatial position, and introduce a recursive neural network with simple gating function. We also feed input embeddings for every layers as skip connections to accelerate the training. Experimental results show that our model achieves the state-of-the-art performance on the standard benchmark dataset for molecular property prediction.}}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{10.1038/s41467-019-10827-4, \n",
    "  author = {Smith, Justin S and Nebgen, Benjamin T and Zubatyuk, Roman and Lubbers, Nicholas and Devereux, Christian and Barros, Kipton and Tretiak, Sergei and Isayev, Olexandr and Roitberg, Adrian E}, \n",
    "  title = {{Approaching coupled cluster accuracy with a general-purpose neural network potential through transfer learning}}, \n",
    "  doi = {10.1038/s41467-019-10827-4}, \n",
    "  pmid = {31263102}, \n",
    "  abstract = {{Computational modeling of chemical and biological systems at atomic resolution is a crucial tool in the chemist’s toolset. The use of computer simulations requires a balance between cost and accuracy: quantum-mechanical methods provide high accuracy but are computationally expensive and scale poorly to large systems, while classical force fields are cheap and scalable, but lack transferability to new systems. Machine learning can be used to achieve the best of both approaches. Here we train a general-purpose neural network potential (ANI-1ccx) that approaches CCSD(T)/CBS accuracy on benchmarks for reaction thermochemistry, isomerization, and drug-like molecular torsions. This is achieved by training a network to DFT data then using transfer learning techniques to retrain on a dataset of gold standard QM calculations (CCSD(T)/CBS) that optimally spans chemical space. The resulting potential is broadly applicable to materials science, biology, and chemistry, and billions of times faster than CCSD(T)/CBS calculations. Computational modelling of chemical systems requires a balance between accuracy and computational cost. Here the authors use transfer learning to develop a general purpose neural network potential that approaches quantum-chemical accuracy for reaction thermochemistry, isomerization, and drug-like molecular torsions.}}, \n",
    "  pages = {2903}, \n",
    "  number = {1}, \n",
    "  volume = {10}, \n",
    "  journal = {Nature Communications}, \n",
    "  year = {2019}\n",
    "}\n",
    "@article{10.1063/1.5023802, \n",
    "  author = {Smith, Justin S and Nebgen, Ben and Lubbers, Nicholas and Isayev, Olexandr and Roitberg, Adrian E}, \n",
    "  title = {{Less is more: Sampling chemical space with active learning}}, \n",
    "  issn = {0021-9606}, \n",
    "  doi = {10.1063/1.5023802}, \n",
    "  pmid = {29960353}, \n",
    "  eprint = {1801.09319}, \n",
    "  abstract = {{The development of accurate and transferable machine learning (ML) potentials for predicting molecular energetics is a challenging task. The process of data generation to train such ML potentials is a task neither well understood nor researched in detail. In this work, we present a fully automated approach for the generation of datasets with the intent of training universal ML potentials. It is based on the concept of active learning (AL) via Query by Committee (QBC), which uses the disagreement between an ensemble of ML potentials to infer the reliability of the ensemble's prediction. QBC allows the presented AL algorithm to automatically sample regions of chemical space where the ML potential fails to accurately predict the potential energy. AL improves the overall fitness of ANAKIN-ME (ANI) deep learning potentials in rigorous test cases by mitigating human biases in deciding what new training data to use. AL also reduces the training set size to a fraction of the data required when using naive random sampling techniques. To provide validation of our AL approach we develop the COMP6 benchmark (publicly available on GitHub), which contains a diverse set of organic molecules. Through the AL process, it is shown that the AL-based potentials perform as well as the ANI-1 potential on COMP6 with only 10\\% of the data, and vastly outperforms ANI-1 with 25\\% the amount of data. Finally, we show that our proposed AL technique develops a universal ANI potential (ANI-1x) that provides accurate energy and force predictions on the entire COMP6 benchmark. This universal ML potential achieves a level of accuracy on par with the best ML potentials for single molecule or materials, while remaining applicable to the general class of organic molecules comprised of the elements CHNO.}}, \n",
    "  pages = {241733}, \n",
    "  number = {24}, \n",
    "  volume = {148}, \n",
    "  journal = {The Journal of Chemical Physics}, \n",
    "  year = {2018}\n",
    "}\n",
    "@article{10.1021/acsmedchemlett.8b00437, \n",
    "  author = {Smith, Justin S and Roitberg, Adrian E and Isayev, Olexandr}, \n",
    "  title = {{Transforming Computational Drug Discovery with Machine Learning and AI}}, \n",
    "  issn = {1948-5875}, \n",
    "  doi = {10.1021/acsmedchemlett.8b00437}, \n",
    "  pmid = {30429945}, \n",
    "  abstract = {{In this Viewpoint, we discuss the current progress in applications of machine learning (ML) and artificial intelligence (AI) to meet the challenges of computational drug discovery. We identify several areas where existing methods have the potential to accelerate pharmaceutical research and disrupt more traditional approaches.}}, \n",
    "  pages = {1065--1069}, \n",
    "  number = {11}, \n",
    "  volume = {9}, \n",
    "  journal = {ACS Medicinal Chemistry Letters}, \n",
    "  year = {2018}\n",
    "}\n",
    "@article{10.1021/acs.jcim.9b00325, \n",
    "  author = {Ståhl, Niclas and Falkman, Göran and Karlsson, Alexander and Mathiason, Gunnar and Boström, Jonas}, \n",
    "  title = {{Deep Reinforcement Learning for Multiparameter Optimization in de novo Drug Design}}, \n",
    "  issn = {1549-9596}, \n",
    "  doi = {10.1021/acs.jcim.9b00325}, \n",
    "  pmid = {31273995}, \n",
    "  abstract = {{In medicinal chemistry programs it is key to design and make compounds that are efficacious and safe. This is a long, complex, and difficult multiparameter optimization process, often including several properties with orthogonal trends. New methods for the automated design of compounds against profiles of multiple properties are thus of great value. Here we present a fragment-based reinforcement learning approach based on an actor-critic model, for the generation of novel molecules with optimal properties. The actor and the critic are both modeled with bidirectional long short-term memory (LSTM) networks. The AI method learns how to generate new compounds with desired properties by starting from an initial set of lead molecules and then improving these by replacing some of their fragments. A balanced binary tree based on the similarity of fragments is used in the generative process to bias the output toward structurally similar molecules. The method is demonstrated by a case study showing that 93\\% of the generated molecules are chemically valid and more than a third satisfy the targeted objectives, while there were none in the initial set.}}, \n",
    "  pages = {3166--3176}, \n",
    "  number = {7}, \n",
    "  volume = {59}, \n",
    "  journal = {Journal of Chemical Information and Modeling}, \n",
    "  year = {2019}\n",
    "}\n",
    "\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other functionality\n",
    "### Convert jupyter notebook into slides\n",
    "Please refer to this [article](https://medium.com/@mjspeck/presenting-code-using-jupyter-notebook-slides-a8a3c3b59d67)\n",
    "\n",
    "Then we need to \n",
    "```jupyter nbconvert notebook.ipynb --to slides --post serve```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
